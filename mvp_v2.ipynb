{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "H2Mvp0SQgnOH",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2Mvp0SQgnOH",
        "outputId": "9a54533f-e8e8-496e-937c-136c6dbbc1bc"
      },
      "outputs": [],
      "source": [
        "!unzip audios-20250626T230813Z-1-001.zip -d audios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "JvStYmCmhVmt",
      "metadata": {
        "id": "JvStYmCmhVmt"
      },
      "outputs": [],
      "source": [
        "!mkdir working\n",
        "!mkdir working/audio-images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a2a3b571",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2a3b571",
        "outputId": "4a2fe196-ced8-4ff4-8a0a-3ee9bfb9d573"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import os, wave, pylab, itertools\n",
        "from pathlib import Path\n",
        "from scipy import signal\n",
        "from scipy.io import wavfile\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# setando os caminhos\n",
        "INPUT_DIR = 'audios/'\n",
        "OUTPUT_DIR = 'working/'\n",
        "\n",
        "# Print names of 10 WAV files from the input path\n",
        "parent_list = os.listdir(INPUT_DIR)\n",
        "for i in range(10):\n",
        "    print(parent_list[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "52c02088",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "52c02088",
        "outputId": "fa3a02d4-4267-4fe5-8df3-bfc47e6814b9"
      },
      "outputs": [],
      "source": [
        "for i in range(5):\n",
        "    signal_wave = wave.open(os.path.join(INPUT_DIR, parent_list[i]), 'r')\n",
        "    sample_rate = 16000\n",
        "    sig = np.frombuffer(signal_wave.readframes(sample_rate), dtype=np.int16)\n",
        "\n",
        "    plt.figure(figsize=(12,12))\n",
        "    plot_a = plt.subplot(211)\n",
        "    plot_a.set_title(parent_list[i])\n",
        "    plot_a.plot(sig)\n",
        "    plot_a.set_xlabel('taxa do exemplo * tempo')\n",
        "    plot_a.set_ylabel('energy')\n",
        "\n",
        "    plot_b = plt.subplot(212)\n",
        "    plot_b.specgram(sig, NFFT=1024, Fs=sample_rate, noverlap=900)\n",
        "    plot_b.set_xlabel('Time')\n",
        "    plot_b.set_ylabel('Frequency')\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4b417dca",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4b417dca",
        "outputId": "e31eb6ad-d61c-4528-c1e1-a2b3aeebea19"
      },
      "outputs": [],
      "source": [
        "# função de utilidade para obter informações de som e taxa de quadros\n",
        "def get_wav_info(wav_file):\n",
        "    wav = wave.open(wav_file, 'r')\n",
        "    frames = wav.readframes(-1)\n",
        "    sound_info = pylab.frombuffer(frames, 'int16')\n",
        "    frame_rate = wav.getframerate()\n",
        "    wav.close()\n",
        "    return sound_info, frame_rate\n",
        "\n",
        "# para todo audio, vamos fazer o espectrograma e salvar com a label que ele pertence\n",
        "if not os.path.exists(os.path.join(OUTPUT_DIR, 'audio-images')):\n",
        "    os.mkdir(os.path.join(OUTPUT_DIR, 'audio-images'))\n",
        "\n",
        "for filename in os.listdir(INPUT_DIR):\n",
        "    if \"wav\" in filename:\n",
        "        file_path = os.path.join(INPUT_DIR, filename)\n",
        "        file_stem = Path(file_path).stem\n",
        "        target_dir = f'class_{file_stem[0]}'\n",
        "        dist_dir = os.path.join(os.path.join(OUTPUT_DIR, 'audio-images'), target_dir)\n",
        "        file_dist_path = os.path.join(dist_dir, file_stem)\n",
        "        if not os.path.exists(file_dist_path + '.png'):\n",
        "            if not os.path.exists(dist_dir):\n",
        "                os.mkdir(dist_dir)\n",
        "            file_stem = Path(file_path).stem\n",
        "            sound_info, frame_rate = get_wav_info(file_path)\n",
        "            pylab.specgram(sound_info, Fs=frame_rate)\n",
        "            pylab.savefig(f'{file_dist_path}.png')\n",
        "            pylab.close()\n",
        "\n",
        "# printar as 10 classes que tem no data\n",
        "path_list = os.listdir(os.path.join(OUTPUT_DIR, 'audio-images'))\n",
        "print(\"Classes: \\n\")\n",
        "for i in range(10):\n",
        "    print(path_list[i])\n",
        "\n",
        "# nome dos arquivos para a classe 1\n",
        "path_list = os.listdir(os.path.join(OUTPUT_DIR, 'audio-images/class_1'))\n",
        "print(\"\\nA few example files: \\n\")\n",
        "for i in range(10):\n",
        "    print(path_list[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "09fbe6dd",
      "metadata": {
        "id": "09fbe6dd",
        "outputId": "7265dc72-b1b0-4e06-fd7a-e66737839550"
      },
      "outputs": [],
      "source": [
        "# constantes\n",
        "IMAGE_HEIGHT = 256\n",
        "IMAGE_WIDTH = 256\n",
        "BATCH_SIZE = 32\n",
        "N_CHANNELS = 3\n",
        "N_CLASSES = 10\n",
        "\n",
        "# criando um dataset contendo o espectrograma de treino\n",
        "train_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             validation_split=0.2,\n",
        "                                             directory=os.path.join(OUTPUT_DIR, 'audio-images'),\n",
        "                                             shuffle=True,\n",
        "                                             color_mode='rgb',\n",
        "                                             image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
        "                                             subset=\"training\",\n",
        "                                             seed=0)\n",
        "\n",
        "# criando um dataset contendo o espectrograma de validação\n",
        "valid_dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
        "                                             batch_size=BATCH_SIZE,\n",
        "                                             validation_split=0.2,\n",
        "                                             directory=os.path.join(OUTPUT_DIR, 'audio-images'),\n",
        "                                             shuffle=True,\n",
        "                                             color_mode='rgb',\n",
        "                                             image_size=(IMAGE_HEIGHT, IMAGE_WIDTH),\n",
        "                                             subset=\"validation\",\n",
        "                                             seed=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0b7fa57c",
      "metadata": {
        "id": "0b7fa57c",
        "outputId": "a0b21943-aca7-47c8-801c-a9092fe63c03"
      },
      "outputs": [],
      "source": [
        "# gerando rapida visualização dos dados\n",
        "plt.figure(figsize=(12, 12))\n",
        "for images, labels in train_dataset.take(1):\n",
        "    for i in range(9):\n",
        "        ax = plt.subplot(3, 3, i + 1)\n",
        "        plt.imshow(images[i].numpy().astype(\"uint8\"))\n",
        "        plt.title(int(labels[i]))\n",
        "        plt.axis(\"off\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "09be6dc9",
      "metadata": {
        "id": "09be6dc9"
      },
      "source": [
        "antes de podermos construir nosso modelo e começar o treinamento, nós precisamos aplicar um simples augmentation. Nós vamos reecriar a escala do nosso input de (0, 255) para ser (0, 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "303a65c5",
      "metadata": {
        "id": "303a65c5"
      },
      "outputs": [],
      "source": [
        "# Function to prepare our datasets for modelling\n",
        "def prepare(ds, augment=False):\n",
        "    # Define our one transformation\n",
        "    rescale = tf.keras.Sequential([tf.keras.layers.Rescaling(1./255)])\n",
        "    flip_and_rotate = tf.keras.Sequential([\n",
        "        tf.keras.layers.RandomFlip(\"horizontal_and_vertical\"),\n",
        "        tf.keras.layers.RandomRotation(0.2)\n",
        "    ])\n",
        "\n",
        "    # Apply rescale to both datasets and augmentation only to training\n",
        "    ds = ds.map(lambda x, y: (rescale(x, training=True), y))\n",
        "    if augment: ds = ds.map(lambda x, y: (flip_and_rotate(x, training=True), y))\n",
        "    return ds\n",
        "\n",
        "train_dataset = prepare(train_dataset, augment=False)\n",
        "valid_dataset = prepare(valid_dataset, augment=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "62d6d38a",
      "metadata": {
        "id": "62d6d38a",
        "outputId": "0b599ee2-3647-4bc9-82c0-4bbcfc2c68a1"
      },
      "outputs": [],
      "source": [
        "# criando a CNN com o keras para ser rapido\n",
        "model = tf.keras.models.Sequential()\n",
        "model.add(tf.keras.layers.Input(shape=(IMAGE_HEIGHT, IMAGE_WIDTH, N_CHANNELS)))\n",
        "model.add(tf.keras.layers.Conv2D(32, 3, strides=2, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Conv2D(64, 3, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Conv2D(128, 3, padding='same', activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Flatten())\n",
        "model.add(tf.keras.layers.Dense(256, activation='relu'))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Dropout(0.5))\n",
        "model.add(tf.keras.layers.Dense(N_CLASSES, activation='softmax'))\n",
        "\n",
        "# Compile model\n",
        "model.compile(\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    optimizer=tf.keras.optimizers.RMSprop(),\n",
        "    metrics=['accuracy'],\n",
        ")\n",
        "\n",
        "# Train model for 10 epochs, capture the history\n",
        "history = model.fit(train_dataset, epochs=10, validation_data=valid_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e129106",
      "metadata": {
        "id": "8e129106",
        "outputId": "289fc070-18ec-441e-f98f-2f74437245b0"
      },
      "outputs": [],
      "source": [
        "# Plot the loss curves for training and validation.\n",
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "epochs = range(1, len(loss_values)+1)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3609ca8f",
      "metadata": {
        "id": "3609ca8f",
        "outputId": "611af4b4-2919-4691-caa7-f567724adeb2"
      },
      "outputs": [],
      "source": [
        "# Plot the accuracy curves for training and validation.\n",
        "acc_values = history_dict['accuracy']\n",
        "val_acc_values = history_dict['val_accuracy']\n",
        "epochs = range(1, len(acc_values)+1)\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.plot(epochs, acc_values, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc_values, 'b', label='Validation accuracy')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81b97564",
      "metadata": {
        "id": "81b97564",
        "outputId": "23b60f39-c651-48f7-b7c4-a338b34630f1"
      },
      "outputs": [],
      "source": [
        "# Compute the final loss and accuracy\n",
        "final_loss, final_acc = model.evaluate(valid_dataset, verbose=0)\n",
        "print(\"Final loss: {0:.6f}, final accuracy: {1:.6f}\".format(final_loss, final_acc))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34db3682",
      "metadata": {
        "id": "34db3682",
        "outputId": "4fe12f6d-6e29-43f1-e1ac-cc008f2c6a7b"
      },
      "outputs": [],
      "source": [
        "predictions = model.predict(valid_dataset)\n",
        "predicted_classes = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Obter as labels verdadeiras\n",
        "true_labels = []\n",
        "for _, labels in valid_dataset:\n",
        "    true_labels.extend(labels.numpy())\n",
        "true_labels = np.array(true_labels)\n",
        "\n",
        "# Criar matriz de confusão\n",
        "cm = confusion_matrix(true_labels, predicted_classes)\n",
        "\n",
        "plt.figure(figsize=(10, 8))\n",
        "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
        "plt.title('Matriz de Confusão')\n",
        "plt.colorbar()\n",
        "tick_marks = np.arange(N_CLASSES)\n",
        "plt.xticks(tick_marks, [f'Classe {i}' for i in range(N_CLASSES)], rotation=45)\n",
        "plt.yticks(tick_marks, [f'Classe {i}' for i in range(N_CLASSES)])\n",
        "plt.ylabel('Classe Verdadeira')\n",
        "plt.xlabel('Classe Predita')\n",
        "\n",
        "# Adicionar valores nas células\n",
        "thresh = cm.max() / 2.\n",
        "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "    plt.text(j, i, format(cm[i, j], 'd'),\n",
        "             horizontalalignment=\"center\",\n",
        "             color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "830d0653",
      "metadata": {
        "id": "830d0653",
        "outputId": "d9fbcc34-2113-4f70-c8f3-fdf8658b5bef"
      },
      "outputs": [],
      "source": [
        "# 2. Gráfico combinado de Loss e Accuracy\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
        "\n",
        "# Loss\n",
        "ax1.plot(epochs, loss_values, 'bo-', label='Training loss', linewidth=2)\n",
        "ax1.plot(epochs, val_loss_values, 'ro-', label='Validation loss', linewidth=2)\n",
        "ax1.set_title('Training and Validation Loss')\n",
        "ax1.set_xlabel('Epochs')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Accuracy\n",
        "ax2.plot(epochs, acc_values, 'bo-', label='Training accuracy', linewidth=2)\n",
        "ax2.plot(epochs, val_acc_values, 'ro-', label='Validation accuracy', linewidth=2)\n",
        "ax2.set_title('Training and Validation Accuracy')\n",
        "ax2.set_xlabel('Epochs')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adc58ab3",
      "metadata": {
        "id": "adc58ab3",
        "outputId": "40c8d497-bf7d-4a2f-8036-7a9775290290"
      },
      "outputs": [],
      "source": [
        "# 3. Distribuição de Confiança das Predições\n",
        "confidence_scores = np.max(predictions, axis=1)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(confidence_scores, bins=30, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "plt.title('Distribuição de Confiança das Predições')\n",
        "plt.xlabel('Score de Confiança')\n",
        "plt.ylabel('Frequência')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.axvline(np.mean(confidence_scores), color='red', linestyle='--',\n",
        "           label=f'Média: {np.mean(confidence_scores):.3f}')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "178f2f16",
      "metadata": {
        "id": "178f2f16",
        "outputId": "a3e27d4c-27a4-4400-e576-e92ea06d90d0"
      },
      "outputs": [],
      "source": [
        "class_accuracy = []\n",
        "for i in range(N_CLASSES):\n",
        "    class_mask = (true_labels == i)\n",
        "    class_pred = predicted_classes[class_mask]\n",
        "    class_true = true_labels[class_mask]\n",
        "    if len(class_true) > 0:\n",
        "        accuracy = np.mean(class_pred == class_true)\n",
        "        class_accuracy.append(accuracy)\n",
        "    else:\n",
        "        class_accuracy.append(0)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(range(N_CLASSES), class_accuracy, color='lightgreen', alpha=0.7)\n",
        "plt.title('Acurácia por Classe')\n",
        "plt.xlabel('Classe')\n",
        "plt.ylabel('Acurácia')\n",
        "plt.xticks(range(N_CLASSES), [f'Classe {i}' for i in range(N_CLASSES)])\n",
        "plt.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Adicionar valores nas barras\n",
        "for i, bar in enumerate(bars):\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
        "             f'{height:.3f}', ha='center', va='bottom')\n",
        "\n",
        "plt.ylim(0, 1.1)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cde3e43b",
      "metadata": {
        "id": "cde3e43b",
        "outputId": "3813d28b-2492-4c40-efc5-403d602d92f2"
      },
      "outputs": [],
      "source": [
        "# 5. Heatmap de Precisão, Recall e F1-Score\n",
        "from sklearn.metrics import classification_report\n",
        "import seaborn as sns\n",
        "\n",
        "# Gerar relatório de classificação\n",
        "report = classification_report(true_labels, predicted_classes,\n",
        "                             target_names=[f'Classe {i}' for i in range(N_CLASSES)],\n",
        "                             output_dict=True)\n",
        "\n",
        "# Extrair métricas\n",
        "metrics_df = pd.DataFrame(report).transpose()\n",
        "metrics_df = metrics_df.drop(['accuracy', 'macro avg', 'weighted avg'])\n",
        "metrics_df = metrics_df[['precision', 'recall', 'f1-score']]\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(metrics_df, annot=True, cmap='YlOrRd', fmt='.3f', cbar_kws={'label': 'Score'})\n",
        "plt.title('Métricas por Classe (Precision, Recall, F1-Score)')\n",
        "plt.ylabel('Classes')\n",
        "plt.xlabel('Métricas')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73ce9a1d",
      "metadata": {
        "id": "73ce9a1d",
        "outputId": "d10ab591-639e-40b9-f083-ca49402b19a1"
      },
      "outputs": [],
      "source": [
        "# 6. Resumo das Métricas\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"RESUMO DAS MÉTRICAS DO MODELO\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Acurácia Final: {final_acc:.4f}\")\n",
        "print(f\"Loss Final: {final_loss:.4f}\")\n",
        "print(f\"Confiança Média: {np.mean(confidence_scores):.4f}\")\n",
        "print(f\"Melhor Época (Validation Accuracy): {np.argmax(val_acc_values) + 1}\")\n",
        "print(f\"Melhor Validation Accuracy: {np.max(val_acc_values):.4f}\")\n",
        "print(f\"Overfitting Score: {max(acc_values) - max(val_acc_values):.4f}\")\n",
        "print(\"=\"*50)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "uB-B5cTOOeXj",
      "metadata": {
        "id": "uB-B5cTOOeXj"
      },
      "source": [
        "## YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "eyoHZNnTcdud",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyoHZNnTcdud",
        "outputId": "08e001c1-55f6-4e83-d12f-68153fa7ba5c"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5WLSQPKPdCSl",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5WLSQPKPdCSl",
        "outputId": "a204f138-9986-4c8c-e484-58cc04d06b6f"
      },
      "outputs": [],
      "source": [
        "!ls /gdrive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "tTXW29Q7YrHa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "tTXW29Q7YrHa",
        "outputId": "86f13695-0bc5-437a-f091-c686586920d2"
      },
      "outputs": [],
      "source": [
        "import gdown\n",
        "\n",
        "file_id = '1q088GgS16uhe5B4o8oFwfWuH9uzhnaWE'\n",
        "url = f'https://drive.google.com/drive/folders/1q088GgS16uhe5B4o8oFwfWuH9uzhnaWE?usp=sharing'\n",
        "\n",
        "gdown.download_folder(url, quiet=True, use_cookies=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "P55hlLxwcchr",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P55hlLxwcchr",
        "outputId": "91554889-bc3a-46a4-d2b0-44e7f4152a5c"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6La83HGxOfzP",
      "metadata": {
        "id": "6La83HGxOfzP"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import shutil\n",
        "import random\n",
        "from pathlib import Path\n",
        "\n",
        "INPUT_IMAGES = \"/content/drive/MyDrive/working/audio-images\"\n",
        "DATASET_DIR = \"dataset\"\n",
        "CLASSES = sorted(os.listdir(INPUT_IMAGES))  # Ex: ['class_0', 'class_1', ..., 'class_9']\n",
        "\n",
        "# Criar estrutura de diretórios\n",
        "for split in ['train', 'val']:\n",
        "    os.makedirs(f\"{DATASET_DIR}/images/{split}\", exist_ok=True)\n",
        "    os.makedirs(f\"{DATASET_DIR}/labels/{split}\", exist_ok=True)\n",
        "\n",
        "# Divisão e criação dos arquivos\n",
        "for i, class_dir in enumerate(CLASSES):\n",
        "    img_paths = glob.glob(os.path.join(INPUT_IMAGES, class_dir, '*.png'))\n",
        "    random.shuffle(img_paths)\n",
        "    split_point = int(0.8 * len(img_paths))\n",
        "    train_imgs, val_imgs = img_paths[:split_point], img_paths[split_point:]\n",
        "\n",
        "    for split, imgs in zip(['train', 'val'], [train_imgs, val_imgs]):\n",
        "        for img_path in imgs:\n",
        "            # Copiar imagem\n",
        "            img_name = Path(img_path).name\n",
        "            dst_img_path = f\"{DATASET_DIR}/images/{split}/{img_name}\"\n",
        "            shutil.copyfile(img_path, dst_img_path)\n",
        "\n",
        "            # Criar label ocupando toda a imagem (classe_id x_center y_center width height)\n",
        "            label_name = img_name.replace(\".png\", \".txt\")\n",
        "            with open(f\"{DATASET_DIR}/labels/{split}/{label_name}\", \"w\") as f:\n",
        "                f.write(f\"{i} 0.5 0.5 1.0 1.0\\n\")  # ocupa toda a imagem\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GbIAFdz9kJNt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GbIAFdz9kJNt",
        "outputId": "625a83d1-61ab-4108-f579-95b1485b974e"
      },
      "outputs": [],
      "source": [
        "%%writefile dataset/dataset.yaml\n",
        "path: ../dataset\n",
        "train: images/train\n",
        "val: images/val\n",
        "nc: 10\n",
        "names:\n",
        "  - class_0\n",
        "  - class_1\n",
        "  - class_2\n",
        "  - class_3\n",
        "  - class_4\n",
        "  - class_5\n",
        "  - class_6\n",
        "  - class_7\n",
        "  - class_8\n",
        "  - class_9\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BJ17fK7YkT3_",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BJ17fK7YkT3_",
        "outputId": "d20b5fbc-592d-4850-ebbf-1c596469d16f"
      },
      "outputs": [],
      "source": [
        "!pip install ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "BBEaWjdTkx0Q",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BBEaWjdTkx0Q",
        "outputId": "949e881d-9839-4541-b5d6-df4457b706c7"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Verificar se CUDA (GPU) está disponível\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9kH6Afj6kRMX",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9kH6Afj6kRMX",
        "outputId": "d79a0ccd-acb0-4526-9da5-0ca9817f57dc"
      },
      "outputs": [],
      "source": [
        "from ultralytics import YOLO\n",
        "\n",
        "model = YOLO('yolov8n.pt')\n",
        "\n",
        "model.to(device)\n",
        "\n",
        "history = model.train(\n",
        "    data='dataset/dataset.yaml',\n",
        "    epochs=10,\n",
        "    imgsz=256,\n",
        "    batch=16,\n",
        "    device=device,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "idFtwJe5Z-It",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "idFtwJe5Z-It",
        "outputId": "f597a8d0-f2bf-47fe-cde1-1c65cd77adee"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Dados de treinamento (substitua os valores pelos dados reais do seu treino)\n",
        "epochs = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
        "\n",
        "# Métricas durante as épocas\n",
        "box_loss = [0.272, 0.1832, 0.1644, 0.1511, 0.1324, 0.1147, 0.101, 0.08938, 0.08272, 0.07154]\n",
        "cls_loss = [2.723, 1.873, 1.411, 1.054, 0.8269, 0.69, 0.5685, 0.4876, 0.3936, 0.3545]\n",
        "dfl_loss = [0.9615, 0.9175, 0.8979, 0.8855, 0.8696, 0.8736, 0.8697, 0.8624, 0.859, 0.8567]\n",
        "precision = [0.138, 0.365, 0.593, 0.865, 0.814, 0.93, 0.945, 0.972, 0.983, 0.975]\n",
        "recall = [0.757, 0.589, 0.698, 0.744, 0.868, 0.915, 0.948, 0.963, 0.982, 0.99]\n",
        "map50 = [0.227, 0.384, 0.72, 0.894, 0.928, 0.982, 0.988, 0.988, 0.994, 0.994]\n",
        "map50_95 = [0.227, 0.382, 0.702, 0.889, 0.925, 0.981, 0.988, 0.987, 0.993, 0.994]\n",
        "\n",
        "# Plotando os gráficos\n",
        "\n",
        "fig, axs = plt.subplots(3, 2, figsize=(14, 10))\n",
        "\n",
        "# Box loss\n",
        "axs[0, 0].plot(epochs, box_loss, marker='o', color='b', label='Box Loss')\n",
        "axs[0, 0].set_title('Box Loss')\n",
        "axs[0, 0].set_xlabel('Epochs')\n",
        "axs[0, 0].set_ylabel('Loss')\n",
        "axs[0, 0].grid(True)\n",
        "\n",
        "# Class loss\n",
        "axs[0, 1].plot(epochs, cls_loss, marker='o', color='r', label='Class Loss')\n",
        "axs[0, 1].set_title('Class Loss')\n",
        "axs[0, 1].set_xlabel('Epochs')\n",
        "axs[0, 1].set_ylabel('Loss')\n",
        "axs[0, 1].grid(True)\n",
        "\n",
        "# DFL loss\n",
        "axs[1, 0].plot(epochs, dfl_loss, marker='o', color='g', label='DFL Loss')\n",
        "axs[1, 0].set_title('DFL Loss')\n",
        "axs[1, 0].set_xlabel('Epochs')\n",
        "axs[1, 0].set_ylabel('Loss')\n",
        "axs[1, 0].grid(True)\n",
        "\n",
        "# Precision\n",
        "axs[1, 1].plot(epochs, precision, marker='o', color='c', label='Precision')\n",
        "axs[1, 1].set_title('Precision')\n",
        "axs[1, 1].set_xlabel('Epochs')\n",
        "axs[1, 1].set_ylabel('Precision')\n",
        "axs[1, 1].grid(True)\n",
        "\n",
        "# Recall\n",
        "axs[2, 0].plot(epochs, recall, marker='o', color='m', label='Recall')\n",
        "axs[2, 0].set_title('Recall')\n",
        "axs[2, 0].set_xlabel('Epochs')\n",
        "axs[2, 0].set_ylabel('Recall')\n",
        "axs[2, 0].grid(True)\n",
        "\n",
        "# mAP50\n",
        "axs[2, 1].plot(epochs, map50, marker='o', color='y', label='mAP50')\n",
        "axs[2, 1].set_title('mAP50')\n",
        "axs[2, 1].set_xlabel('Epochs')\n",
        "axs[2, 1].set_ylabel('mAP50')\n",
        "axs[2, 1].grid(True)\n",
        "\n",
        "# Ajustar layout\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Ya39h8bcsszj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Ya39h8bcsszj",
        "outputId": "44d649db-0a31-44ee-a917-8ce4700c429f"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "\n",
        "# Caminho da pasta no Google Drive\n",
        "drive_path = '/content/drive/MyDrive/working/'\n",
        "\n",
        "# Copiar a pasta 'working' para o Google Drive\n",
        "shutil.copytree('working', drive_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "u-QxUtsItl2V",
      "metadata": {
        "id": "u-QxUtsItl2V"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/drive/MyDrive/computer-vision"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5zAr9g8HtbtK",
      "metadata": {
        "id": "5zAr9g8HtbtK"
      },
      "outputs": [],
      "source": [
        "# Salvar os pesos do modelo no Google Drive\n",
        "model.save('/content/drive/MyDrive/computer-vision/model_weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "kF5pkGJ9UmdC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kF5pkGJ9UmdC",
        "outputId": "7545223d-aa1a-4435-b887-1e118b6c2134"
      },
      "outputs": [],
      "source": [
        "history."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "W2SNZb8XWKLc",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "W2SNZb8XWKLc",
        "outputId": "7858e553-2417-40e8-9467-a417214b0414"
      },
      "outputs": [],
      "source": [
        "history.to_df()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_1aB7xacsveC",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "_1aB7xacsveC",
        "outputId": "140df36c-a218-43eb-b8a6-97ccd88364f5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Gerar gráficos de loss\n",
        "history_dict = history\n",
        "loss_values = history_dict.loss\n",
        "val_loss_values = history_dict['val_loss']\n",
        "epochs = range(1, len(loss_values) + 1)\n",
        "\n",
        "# Salvar gráfico de loss\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epochs, loss_values, 'bo', label='Training loss')\n",
        "plt.plot(epochs, val_loss_values, 'b', label='Validation loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.savefig('/content/drive/MyDrive/working/loss_graph.png')  # Salvar no Google Drive\n",
        "plt.close()\n",
        "\n",
        "# Gerar gráfico de accuracy\n",
        "acc_values = history_dict['accuracy']\n",
        "val_acc_values = history_dict['val_accuracy']\n",
        "\n",
        "# Salvar gráfico de accuracy\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(epochs, acc_values, 'bo', label='Training accuracy')\n",
        "plt.plot(epochs, val_acc_values, 'b', label='Validation accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('/content/drive/MyDrive/working/accuracy_graph.png')  # Salvar no Google Drive\n",
        "plt.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qWwyUzo-VKRY",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qWwyUzo-VKRY",
        "outputId": "b0641d33-ccb3-4bb8-ac55-ab6aa0155a04"
      },
      "outputs": [],
      "source": [
        "model.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "X_FODq8NuNrv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "X_FODq8NuNrv",
        "outputId": "3ba09447-dd0e-4800-ac91-426c01674e5b"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# Dados fornecidos\n",
        "metrics = {\n",
        "    'Precision': np.array([0.9983677553068719] * 10),\n",
        "    'Recall': np.array([0.9969186941123175] * 10),\n",
        "    'mAP50': np.array([0.9949999999999999] * 10),\n",
        "    'mAP50-95': np.array([0.995] * 10)\n",
        "}\n",
        "\n",
        "# Chaves das classes\n",
        "class_names = ['class_0', 'class_1', 'class_2', 'class_3', 'class_4', 'class_5', 'class_6', 'class_7', 'class_8', 'class_9']\n",
        "\n",
        "# Fitness\n",
        "fitness = 0.995\n",
        "\n",
        "# Plotting Precision, Recall, mAP50, mAP50-95 por classe\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# Precision\n",
        "axes[0, 0].bar(class_names, metrics['Precision'], color='b')\n",
        "axes[0, 0].set_title('Precision per Class')\n",
        "axes[0, 0].set_xlabel('Classes')\n",
        "axes[0, 0].set_ylabel('Precision')\n",
        "axes[0, 0].tick_params(axis='x', rotation=90)\n",
        "\n",
        "# Recall\n",
        "axes[0, 1].bar(class_names, metrics['Recall'], color='g')\n",
        "axes[0, 1].set_title('Recall per Class')\n",
        "axes[0, 1].set_xlabel('Classes')\n",
        "axes[0, 1].set_ylabel('Recall')\n",
        "axes[0, 1].tick_params(axis='x', rotation=90)\n",
        "\n",
        "# mAP50\n",
        "axes[1, 0].bar(class_names, metrics['mAP50'], color='r')\n",
        "axes[1, 0].set_title('mAP50 per Class')\n",
        "axes[1, 0].set_xlabel('Classes')\n",
        "axes[1, 0].set_ylabel('mAP50')\n",
        "axes[1, 0].tick_params(axis='x', rotation=90)\n",
        "\n",
        "# mAP50-95\n",
        "axes[1, 1].bar(class_names, metrics['mAP50-95'], color='c')\n",
        "axes[1, 1].set_title('mAP50-95 per Class')\n",
        "axes[1, 1].set_xlabel('Classes')\n",
        "axes[1, 1].set_ylabel('mAP50-95')\n",
        "axes[1, 1].tick_params(axis='x', rotation=90)\n",
        "\n",
        "# Ajuste de layout\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Plotting Fitness\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(['Fitness'], [fitness], color='purple')\n",
        "plt.title('Fitness Metric')\n",
        "plt.ylabel('Fitness')\n",
        "plt.show()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
